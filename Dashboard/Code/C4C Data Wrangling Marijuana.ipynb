{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40bfd4d",
   "metadata": {},
   "source": [
    "# Data Wrangling Criminal Expungement Dashboard Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070357c",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67f77f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n/usr/libexec/java_home -V\\nexport JAVA_HOME=/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\\nexport PATH=$JAVA_HOME/bin:$PATH\\nwhich java\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STOP!\n",
    "# Before you do anything, copy the code below. You'll need to shut down the \n",
    "# notebook, close and re-open the terminal and paste this code in *before* you call jupyter notebook.\n",
    "# We need to switch to Java 8 before we can load PySpark functions. \n",
    "'''\n",
    "/usr/libexec/java_home -V\n",
    "export JAVA_HOME=/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\n",
    "export PATH=$JAVA_HOME/bin:$PATH\n",
    "which java\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9b2af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a24beace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/Users/amawest/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15bf11c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_292\"\r\n",
      "OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_292-b10)\r\n",
      "OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.292-b10, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "195e2a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amawest/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/Users/amawest/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (5,27,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/Users/amawest/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (39,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# load in all the raw data from Virginia Open Court Data\n",
    "data_2010 = pd.read_csv('circuit_data/circuit_criminal_2010_anon_00.csv')\n",
    "data_2011 = pd.read_csv('circuit_data/circuit_criminal_2011_anon_00.csv')\n",
    "data_2012 = pd.read_csv('circuit_data/circuit_criminal_2012_anon_00.csv')\n",
    "data_2013 = pd.read_csv('circuit_data/circuit_criminal_2013_anon_00.csv')\n",
    "data_2014 = pd.read_csv('circuit_data/circuit_criminal_2014_anon_00.csv')\n",
    "data_2015 = pd.read_csv('circuit_data/circuit_criminal_2015_anon_00.csv')\n",
    "data_2016 = pd.read_csv('circuit_data/circuit_criminal_2016_anon_00.csv')\n",
    "data_2017 = pd.read_csv('circuit_data/circuit_criminal_2017_anon_00.csv')\n",
    "data_2018 = pd.read_csv('circuit_data/circuit_criminal_2018_anon_00.csv')\n",
    "data_2019 = pd.read_csv('circuit_data/circuit_criminal_2019_anon_00.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7823d8",
   "metadata": {},
   "source": [
    "## Part 2: Adding County Names Based on Zip to Match Census\n",
    "- Note: This function takes a WHILE to run. I have the completed files on Github already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a375c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all data and get the county names based on zip (to match with Census)\n",
    "import addfips\n",
    "import zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2616b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albemarle County\n",
      "Barry County\n"
     ]
    }
   ],
   "source": [
    "# check that the functions work the way they are supposed to knowing zipcodes that you know\n",
    "# this function matches county to zip\n",
    "af = addfips.AddFIPS()\n",
    "# test that it works based on 2 zipcodes --> counties I know\n",
    "info = zipcodes.matching('22901') # my current residence (VA)\n",
    "print(info[0]['county'])\n",
    "info = zipcodes.matching('49046') # my hometown (MI)\n",
    "print(info[0]['county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e41752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counties(file):\n",
    "    \"\"\"Adds the county of residence for every person with a valid zipcode.\"\"\"\n",
    "    \n",
    "    # step 3: we need zipcodes, we we'll need to extract them from the addresses\n",
    "    file[['city_state', 'zip']] = file.Address.str.rsplit(\" \", n=1, expand=True,)\n",
    "    file_zips = file[file['zip'].notnull()]\n",
    "    \n",
    "    # a few zip codes create an error because they don't have a corresponding county,\n",
    "    # this should be rewritten so that the loop happening a few lines later learns\n",
    "    # to just past over these zips to avoid breaking (and for when we add data later)\n",
    "    file_zips = file_zips[~file_zips['zip'].str.contains('-')]\n",
    "    file_zips = file_zips[file_zips['zip'].str.contains('(?<!\\n)[\\d]{5,6}[\\-]?[\\d]*')]\n",
    "    file_zips = file_zips[file_zips['city_state'].str.contains('VA')]\n",
    "    \n",
    "    # create space for few values\n",
    "    file_zips['county'] = 0\n",
    "    file_zips['state']  = 'Virginia'\n",
    "    \n",
    "    # add in the county names \n",
    "    for i in range(0, len(file_zips)):\n",
    "        # we can use try-except here because we don't need the bad zip entries to be included - they will just go\n",
    "        # towards the final \"missing\" chunk, anyways. \n",
    "        if file_zips['county'][i] == 0:\n",
    "            try:\n",
    "                info = zipcodes.matching(list(file_zips['zip'])[i])\n",
    "            except:\n",
    "                pass\n",
    "            if info == []:\n",
    "                pass\n",
    "            else: \n",
    "                file_zips['county'][i] = info[0]['county']\n",
    "        return file_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2010_zips = get_counties(data_2010)\n",
    "data_2011_zips = get_counties(data_2011)\n",
    "data_2012_zips = get_counties(data_2012)\n",
    "data_2013_zips = get_counties(data_2013)\n",
    "data_2014_zips = get_counties(data_2014)\n",
    "data_2015_zips = get_counties(data_2015)\n",
    "data_2016_zips = get_counties(data_2016)\n",
    "data_2017_zips = get_counties(data_2017)\n",
    "data_2018_zips = get_counties(data_2018)\n",
    "data_2019_zips = get_counties(data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe87baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# already saved, so commented out so they are not overwritten\n",
    "'''\n",
    "data_2010_zips.to_csv('circuit_data/zips_circuit_criminal_2010.csv')\n",
    "data_2011_zips.to_csv('circuit_data/zips_circuit_criminal_2011.csv')\n",
    "data_2012_zips.to_csv('circuit_data/zips_circuit_criminal_2012.csv')\n",
    "data_2013_zips.to_csv('circuit_data/zips_circuit_criminal_2013.csv')\n",
    "data_2014_zips.to_csv('circuit_data/zips_circuit_criminal_2014.csv')\n",
    "data_2015_zips.to_csv('circuit_data/zips_circuit_criminal_2015.csv')\n",
    "data_2016_zips.to_csv('circuit_data/zips_circuit_criminal_2016.csv')\n",
    "data_2017_zips.to_csv('circuit_data/zips_circuit_criminal_2017.csv')\n",
    "data_2018_zips.to_csv('circuit_data/zips_circuit_criminal_2018.csv')\n",
    "data_2019_zips.to_csv('circuit_data/zips_circuit_criminal_2019.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6403285",
   "metadata": {},
   "source": [
    "## Part 3: Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dcc12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "# note that we only keep DISTINCT (i.e. unique) person IDs from here on out\n",
    "for i in range(0,10):\n",
    "    infile = (f'circuit_data/zips_circuit_criminal_201{i}.csv')\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Racial Disparity\") \\\n",
    "        .getOrCreate()\n",
    "    circuit = spark.read.csv(infile, inferSchema = True, header = True)\n",
    "    circuit.createOrReplaceTempView(\"data\")\n",
    "    sqlDF = spark.sql(\n",
    "        \n",
    "        # currently set to look at marijuana code sections only\n",
    "        # but just take out codesections to see everything\n",
    "        '''\n",
    "        SELECT COUNT(DISTINCT(person_id)) as Count, Race, Sex, fips FROM data\n",
    "                   WHERE (CodeSection LIKE '18.2-248%' \n",
    "                   OR CodeSection LIKE '18.2-250%'\n",
    "                   OR CodeSection LIKE '18.2-255%')\n",
    "                   GROUP BY Race, fips, Sex\n",
    "                   ORDER BY Count DESC\n",
    "                   '''\n",
    "    )\n",
    "    data = sqlDF.toPandas()\n",
    "    data['Race and Sex'] = data['Race'] + ' - ' + data['Sex']\n",
    "    data = data[['fips', 'Race and Sex', 'Count']]\n",
    "    df_p = data.pivot_table(index=['fips'], columns=['Race and Sex'], values='Count', aggfunc=np.sum)\n",
    "    data_1 = df_p.fillna(0)\n",
    "    data_1.to_csv(f'Data/201{i}_finished.csv')\n",
    "\n",
    "# NOTE: Add/remove as desired to change the type of query\n",
    "# Marijuana\n",
    "# WHERE (CodeSection LIKE '18.2-248%' \n",
    "# OR CodeSection LIKE '18.2-250%'\n",
    "# OR CodeSection LIKE '18.2-255%')\n",
    "\n",
    "# Felonys\n",
    "# AND (ChargeType == 'Felony')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f6976994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('2019_finished.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e1f8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('2018_finished.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1358ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code to rename 2019 to match 2010-2018 column labels (currently not using)\n",
    "x = pd.read_csv('2019_finished.csv')\n",
    "new_cols = {'American Indian Or Alaskan Native - Female':         'American Indian - Female',\n",
    "            'American Indian Or Alaskan Native - Male':           'American Indian - Male',\n",
    "            'Asian Or Pacific Islander - Female':                 'Asian Or Pacific Islander - Female',\n",
    "            'Asian Or Pacific Islander - Male':                   'Asian Or Pacific Islander - Male',\n",
    "            'Black - Female':                                     'Black (Non-Hispanic) - Female',\n",
    "            'Black - Male':                                       'Black (Non-Hispanic) - Male',\n",
    "            'Hispanic - Female':                                  'Hispanic - Female',\n",
    "            'Hispanic - Male':                                    'Hispanic - Male',\n",
    "            'White - Female':                                     'White Caucasian (Non-Hispanic) - Female',\n",
    "            'White - Male':                                       'White Caucasian (Non-Hispanic) - Male',\n",
    "            'Other (Includes Not Applicable, Unknown) - Female':  'Other (Includes Not Applicable, Unknown) - Female',\n",
    "            'Other (Includes Not Applicable, Unknown) - Male':    'Other (Includes Not Applicable, Unknown) - Male',\n",
    "           }\n",
    "x.rename(columns=new_cols,\n",
    "          inplace=True)\n",
    "x.to_csv('Data/2019_finished.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "59c10b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Note: make sure to reset the year each time\\ninfile = \\'Data/census_data_fips.csv\\'\\nspark = SparkSession     .builder     .appName(\"Census Data\")     .getOrCreate()\\ncircuit = spark.read.csv(infile, inferSchema=True, header = True)\\ncircuit.createOrReplaceTempView(\"census_data\")\\nsqlDF = spark.sql(\\'SELECT *                    FROM census_data                    WHERE Year = 2019\\')\\ncensus = sqlDF.toPandas()\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Note: make sure to reset the year each time\n",
    "infile = 'Data/census_data_fips.csv'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Census Data\") \\\n",
    "    .getOrCreate()\n",
    "circuit = spark.read.csv(infile, inferSchema=True, header = True)\n",
    "circuit.createOrReplaceTempView(\"census_data\")\n",
    "sqlDF = spark.sql('SELECT * \\\n",
    "                   FROM census_data \\\n",
    "                   WHERE Year = 2019')\n",
    "census = sqlDF.toPandas()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f4e144d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    # Note: make sure to reset the year each time\n",
    "    infile = 'Data/census_data_fips.csv'\n",
    "    spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Census Data\") \\\n",
    "    .getOrCreate()\n",
    "    circuit = spark.read.csv(infile, inferSchema=True, header = True)\n",
    "    circuit.createOrReplaceTempView(\"census_data\")\n",
    "    sqlDF = spark.sql(f'SELECT * \\\n",
    "                   FROM census_data \\\n",
    "                   WHERE Year = 201{i}')\n",
    "    census = sqlDF.toPandas()\n",
    "    \n",
    "    #--------------------#\n",
    "    data = pd.read_csv(f'Data/201{i}_finished.csv')\n",
    "    #--------------------#\n",
    "    data['Total_Crimes'] = 0\n",
    "    data['Total_Crimes'] = data.sum(axis=1) \n",
    "    data.head(2)\n",
    "    #del census['Year']\n",
    "    census.head(2)\n",
    "    result = pd.merge(census,\n",
    "                  data,\n",
    "                  on='fips', \n",
    "                  how='left')\n",
    "    result.head(2)\n",
    "    data.columns\n",
    "    result['Percent_Overall']          = (result['Total_Crimes']   / result['Total'])*100\n",
    "    result['Percent_White_Male']       = (result['White Caucasian (Non-Hispanic) - Male']   / result['White_Male'])*100\n",
    "    result['Percent_White_Female']     = (result['White Caucasian (Non-Hispanic) - Female'] / result['White_Female'])*100\n",
    "    result['Percent_Black_Male']       = (result['Black (Non-Hispanic) - Male']             / result['Black_Male'])*100\n",
    "    result['Percent_Black_Female']     = (result['Black (Non-Hispanic) - Female']           / result['Black_Female'])*100\n",
    "    result['Percent_Nat_Amer_Male']    = (result['American Indian - Male']                  / result['Native_Amer_Male'])*100\n",
    "    #result['Percent_Nat_Amer_Female']  = (result['American Indian - Female']                / result['Native_Amer_Female'])*100\n",
    "    result['Percent_Hispanic_Male']    = (result['Hispanic - Male']                         / result['Hispanic_Male'])*100\n",
    "    result['Percent_Hispanic_Female']  = (result['Hispanic - Female']                       / result['Hispanic_Female'])*100\n",
    "    result['Percent_Asian_Pac_Male']   = (result['Asian Or Pacific Islander - Male']        / result['Asian_Male'])*100\n",
    "    result['Percent_Asian_Pac_Female'] = (result['Asian Or Pacific Islander - Female']      / result['Asian_Female'])*100\n",
    "    \n",
    "    result['Percent_Overall']            = round(result['Percent_Overall'],3)\n",
    "    result['Disparity_White_Male']       = round(result['Percent_White_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_White_Female']     = round(result['Percent_White_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Black_Male']       = round(result['Percent_Black_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Black_Female']     = round(result['Percent_Black_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Nat_Amer_Male']    = round(result['Percent_Nat_Amer_Male'] - result['Percent_Overall'],3)\n",
    "    #result['Disparity_Nat_Amer_Female']  = round(result['Percent_Nat_Amer_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Hispanic_Male']    = round(result['Percent_Hispanic_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Hispanic_Female']  = round(result['Percent_Hispanic_Female'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Asian_Pac_Male']   = round(result['Percent_Asian_Pac_Male'] - result['Percent_Overall'],3)\n",
    "    result['Disparity_Asian_Pac_Female'] = round(result['Percent_Asian_Pac_Female'] - result['Percent_Overall'],3)\n",
    "    \n",
    "    result = result[['fips', \n",
    "                     'CTYNAME',\n",
    "                     'Percent_Overall',\n",
    "                     'Disparity_White_Male',\n",
    "                     'Disparity_White_Female',\n",
    "                     'Disparity_Black_Male',\n",
    "                     'Disparity_Black_Female', \n",
    "                     'Disparity_Nat_Amer_Male',\n",
    "                     #'Disparity_Nat_Amer_Female', \n",
    "                     'Disparity_Hispanic_Male',\n",
    "                     'Disparity_Hispanic_Female',\n",
    "                     'Disparity_Asian_Pac_Male',\n",
    "                     'Disparity_Asian_Pac_Female'\n",
    "        ]]\n",
    "    result\n",
    "    #--------------------#\n",
    "    result.to_csv(f'Data/Final/201{i}_disparities.csv',index=None)\n",
    "    #--------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ce789",
   "metadata": {},
   "source": [
    "## Part 4: Put It All Together & Finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd6495cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2010 = pd.read_csv('Data/Final/2010_disparities.csv')\n",
    "x_2011 = pd.read_csv('Data/Final/2011_disparities.csv')\n",
    "x_2012 = pd.read_csv('Data/Final/2012_disparities.csv')\n",
    "x_2013 = pd.read_csv('Data/Final/2013_disparities.csv')\n",
    "x_2014 = pd.read_csv('Data/Final/2014_disparities.csv')\n",
    "x_2015 = pd.read_csv('Data/Final/2015_disparities.csv')\n",
    "x_2016 = pd.read_csv('Data/Final/2016_disparities.csv')\n",
    "x_2017 = pd.read_csv('Data/Final/2017_disparities.csv')\n",
    "x_2018 = pd.read_csv('Data/Final/2018_disparities.csv')\n",
    "x_2019 = pd.read_csv('Data/Final/2019_disparities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d768b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2010['year'] = 2010\n",
    "x_2011['year'] = 2011\n",
    "x_2012['year'] = 2012\n",
    "x_2013['year'] = 2013\n",
    "x_2014['year'] = 2014\n",
    "x_2015['year'] = 2015\n",
    "x_2016['year'] = 2016\n",
    "x_2017['year'] = 2017\n",
    "x_2018['year'] = 2018\n",
    "x_2019['year'] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "69be36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2010.to_csv('Data/Final/2010_disparities.csv')\n",
    "x_2011.to_csv('Data/Final/2011_disparities.csv')\n",
    "x_2012.to_csv('Data/Final/2012_disparities.csv')\n",
    "x_2013.to_csv('Data/Final/2013_disparities.csv')\n",
    "x_2014.to_csv('Data/Final/2014_disparities.csv')\n",
    "x_2015.to_csv('Data/Final/2015_disparities.csv')\n",
    "x_2016.to_csv('Data/Final/2016_disparities.csv')\n",
    "x_2017.to_csv('Data/Final/2017_disparities.csv')\n",
    "x_2018.to_csv('Data/Final/2018_disparities.csv')\n",
    "x_2019.to_csv('Data/Final/2019_disparities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a2f1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Data/Final/2010_disparities.csv',\n",
    "         'Data/Final/2011_disparities.csv',\n",
    "         'Data/Final/2012_disparities.csv',\n",
    "         'Data/Final/2013_disparities.csv',\n",
    "         'Data/Final/2014_disparities.csv',\n",
    "         'Data/Final/2015_disparities.csv',\n",
    "         'Data/Final/2016_disparities.csv',\n",
    "         'Data/Final/2017_disparities.csv',\n",
    "         'Data/Final/2018_disparities.csv',\n",
    "         'Data/Final/2019_disparities.csv'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b65da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(f, sep=\",\") for f in files]\n",
    "all_files = pd.concat(dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "493fea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_files['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "338c2562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>Percent_Overall</th>\n",
       "      <th>Disparity_White_Male</th>\n",
       "      <th>Disparity_White_Female</th>\n",
       "      <th>Disparity_Black_Male</th>\n",
       "      <th>Disparity_Black_Female</th>\n",
       "      <th>Disparity_Nat_Amer_Male</th>\n",
       "      <th>Disparity_Hispanic_Male</th>\n",
       "      <th>Disparity_Hispanic_Female</th>\n",
       "      <th>Disparity_Asian_Pac_Male</th>\n",
       "      <th>Disparity_Asian_Pac_Female</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Accomack County</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.463</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Albemarle County</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Alleghany County</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>6.607</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Amelia County</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Amherst County</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips           CTYNAME  Percent_Overall  Disparity_White_Male  \\\n",
       "0     1   Accomack County            0.136                -0.039   \n",
       "1     3  Albemarle County            0.061                -0.010   \n",
       "2     5  Alleghany County            0.704                -0.029   \n",
       "3     7     Amelia County            0.251                -0.062   \n",
       "4     9    Amherst County            0.219                -0.018   \n",
       "\n",
       "   Disparity_White_Female  Disparity_Black_Male  Disparity_Black_Female  \\\n",
       "0                  -0.127                 0.463                  -0.017   \n",
       "1                  -0.052                 0.450                   0.017   \n",
       "2                  -0.368                 6.607                   0.640   \n",
       "3                  -0.188                 0.632                  -0.187   \n",
       "4                  -0.128                 0.575                  -0.156   \n",
       "\n",
       "   Disparity_Nat_Amer_Male  Disparity_Hispanic_Male  \\\n",
       "0                   -0.136                   -0.136   \n",
       "1                   -0.061                    0.145   \n",
       "2                   -0.704                   -0.704   \n",
       "3                   -0.251                   -0.251   \n",
       "4                   -0.219                   -0.219   \n",
       "\n",
       "   Disparity_Hispanic_Female  Disparity_Asian_Pac_Male  \\\n",
       "0                     -0.136                    -0.136   \n",
       "1                     -0.061                    -0.061   \n",
       "2                     -0.704                    -0.704   \n",
       "3                     -0.251                    -0.251   \n",
       "4                     -0.219                    -0.219   \n",
       "\n",
       "   Disparity_Asian_Pac_Female  year  \n",
       "0                      -0.136  2010  \n",
       "1                      -0.061  2010  \n",
       "2                      -0.704  2010  \n",
       "3                      -0.251  2010  \n",
       "4                      -0.219  2010  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ed7974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files.to_csv('all_files_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64412287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
