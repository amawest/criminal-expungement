{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Felony Modeling\n",
    "\n",
    "Code for Charlottesville is collaborating with the LAJC to examine Virginia criminal court data and advocate for expungement of certain criminal records. As part of this project, they are interested in whether and how racial bias may play a role in case outcomes. One question of interest is what factors are predictive of whether someone is charged with a felony or a misdemeanor for a particular crime.\n",
    "\n",
    "To investigate this question, we implement logistic regression and random forest classification models using felony/misdemeanor as the target predictor variable. We use race along with other predictor variables to see how much impact race has on charge type. We are particularly interested in marijuana charges, since the recent legalization of marijuana in Virginia has made prior marijuana charges a particular priority for expungement.\n",
    "\n",
    "### Summary\n",
    "\n",
    "Using these techniques, we found that race did not make much difference in the rates at which people were charged with felonies or misdemeanors for charges of marijuana possession with intent to distribute. However, race was more predictive than gender as a predictive demographic attribute for misdemeanor/felony charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and Pre-process Data\n",
    "\n",
    "We begin by looking at the district criminal data from 2019. This data contains just under 2 million records, of which about 650,000 are classified as either a misdemeanor or felony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(\"district_criminal_2019_anon_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most fields are strings, but wanted to create schema so that a few columns are numeric\n",
    "fields = []\n",
    "for f in json.loads(district.schema.json())[\"fields\"]:\n",
    "    if f[\"name\"] in ['SentenceTime', 'ProbationTime', 'Fine', 'Costs', 'FineCostsDue', 'FineCostsPaid']:\n",
    "        fields.append(StructField(f[\"name\"], DoubleType(), True))\n",
    "    else:\n",
    "        fields.append(StructField.fromJson(f))\n",
    "\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = spark.read.schema(schema)\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(\"district_criminal_2019_anon_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning/standardizing race names\n",
    "\n",
    "district = district.withColumn('RaceClean', F.regexp_replace('Race', '\\(Non-Hispanic\\)', ''))\n",
    "district = district.withColumn('RaceClean', F.regexp_replace('RaceClean', ' Caucasian', ''))\n",
    "district = district.withColumn('RaceClean', F.regexp_replace('RaceClean', 'Asian Or', 'Asian or'))\n",
    "district = district.withColumn('RaceClean', F.regexp_replace('RaceClean', ' \\(Includes Not Applicable, Unknown\\)', ''))\n",
    "district = district.withColumn('RaceClean', F.regexp_replace('RaceClean', '\\(Includes Not Applicable, Unknown\\)', ''))\n",
    "district = district.withColumn('RaceClean', F.regexp_replace('RaceClean', 'Other', 'Unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = district.filter(district.CaseType.isin(['Misdemeanor', 'Felony']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('Felony', F.when(data.CaseType == 'Felony', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "\n",
    "To test whether racial bias influences the outcomes, we create a logistic regression model to predict case type (misdemeanor/felony) using code section (code representing crime charged), gender, race, and plea type (innocent/guilty/Nolo Contendere/etc).\n",
    "\n",
    "We chose to use a lasso model because the lasso penalty encourages model coefficients to be equal to zero when they are not contributing significantly to the model. Thus if the coefficients for race are non-zero, we have some evidence that race is useful in predicting whether a crime is a misdemeanor or a felony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all predictor variables are categorical and need to be one-hot encoded before modeling\n",
    "\n",
    "gendInd = StringIndexer(inputCol=\"Gender\", outputCol=\"GendInd\", handleInvalid = \"skip\")\n",
    "gend = OneHotEncoder(inputCol=\"GendInd\", outputCol=\"GenderOH\")\n",
    "\n",
    "raceInd = StringIndexer(inputCol=\"RaceClean\", outputCol=\"RaceInd\", handleInvalid = \"skip\")\n",
    "race = OneHotEncoder(inputCol=\"RaceInd\", outputCol=\"RaceOH\")\n",
    "\n",
    "chargeInd = StringIndexer(inputCol=\"CodeSection\", outputCol=\"ChargeInd\", handleInvalid = \"skip\")\n",
    "charge = OneHotEncoder(inputCol=\"ChargeInd\", outputCol=\"ChargeCodeOH\")\n",
    "\n",
    "#gather encoded predictors into features vector\n",
    "va = VectorAssembler(inputCols=[\"RaceOH\", \"ChargeCodeOH\", \"GenderOH\"], outputCol=\"features\", \n",
    "                     handleInvalid = \"skip\")\n",
    "\n",
    "logm = LogisticRegression(labelCol = 'Felony', elasticNetParam = 1) #lasso = 1, ridge = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gendInd, gend, raceInd, race, chargeInd, charge, va, logm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we would split the data into training and testing sets, but since we're primarily interested in model interpretation rather than prediction, we go ahead and train on the full dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(data)\n",
    "pred = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.9829157611246887\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = model.stages[-1].summary\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "# trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9421483067127724, 0.9150108918080402]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSummary.precisionByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9569337979094077, 0.8875241438922622]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSummary.recallByLabel\n",
    "# https://spark.apache.org/docs/2.4.5/api/python/pyspark.ml.html?highlight=coefficients#pyspark.ml.classification.LogisticRegressionModel.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC tells us that this model is quite successful in predicting whether a charge is a felony or misdemeanor from charge, plea, race, and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 0, 'name': 'RaceOH_White'},\n",
       " {'idx': 1, 'name': 'RaceOH_Black'},\n",
       " {'idx': 2, 'name': 'RaceOH_Hispanic'},\n",
       " {'idx': 3, 'name': 'RaceOH_Unknown'},\n",
       " {'idx': 4, 'name': 'RaceOH_Asian or Pacific Islander'},\n",
       " {'idx': 5, 'name': 'RaceOH_American Indian'},\n",
       " {'idx': 6, 'name': 'ChargeCodeOH_A.46.2-862'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figure out which coefficients map to which characteristics\n",
    "\n",
    "# https://stackoverflow.com/questions/39022052/relating-column-names-to-model-parameters-in-pyspark-ml\n",
    "\n",
    "# numeric_metadata = pred.select(\"features\").schema[0].metadata.get('ml_attr').get('attrs').get('numeric')\n",
    "binary_metadata = pred.select(\"features\").schema[0].metadata.get('ml_attr').get('attrs').get('binary')\n",
    "\n",
    "# merge_list = numeric_metadata + binary_metadata \n",
    "binary_metadata[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.472667565470601\n",
      "-1.5054607141732788\n",
      "-3.1922771686826588\n",
      "-1.909415425831092\n",
      "-1.4324164228370782\n",
      "-1.8795350034162341\n"
     ]
    }
   ],
   "source": [
    "print(model.stages[-1].coefficients[0])\n",
    "print(model.stages[-1].coefficients[1])\n",
    "print(model.stages[-1].coefficients[2])\n",
    "print(model.stages[-1].coefficients[3])\n",
    "print(model.stages[-1].coefficients[4])\n",
    "print(model.stages[-1].coefficients[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the race coefficients are equal to 0, so this is evidence that race does play at least some role in whether someone is charged with a misdemeanor or felony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='White Caucasian(Non-Hispanic)', Gender='Male', probability=DenseVector([0.1572, 0.8428]), prediction=1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.filter(pred.RaceClean == 'White').filter(pred.Gender == 'Male')\\\n",
    "        .filter(pred.CodeSection == '18.2-248.1')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='Black(Non-Hispanic)', Gender='Male', probability=DenseVector([0.1616, 0.8384]), prediction=1.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.filter(pred.RaceClean == 'Black').filter(pred.Gender == 'Male')\\\n",
    "        .filter(pred.CodeSection == '18.2-248.1')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model predicts roughly the same chance of getting charged with a felony for Black and white men. Other races have a small sample size, so we did not consider them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Just Marijuana Charges\n",
    "\n",
    "Next, we create a similar model using just the data for marijuana possession with intent to distribute (code section 18.2-248.1). This charge can be either a misdemeanor or a felony, while marijuana possession (18.2-250.1) is always a misdemeanor. This subset of the data contains 4445 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mj = data.filter(data.CodeSection.isin(['18.2-248.1'])) \n",
    "# this can be felony or misdemeanor (marijuana poss w/ intent to distribute)\n",
    "# 18.2-250.1 is always a misdemeanor (possession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove charge code as a predictor since just one charge included now\n",
    "#one-hot encoding and logistic modeling steps can stay the same\n",
    "\n",
    "va = VectorAssembler(inputCols=[\"RaceOH\", \"GenderOH\"], outputCol=\"features\", \n",
    "                     handleInvalid = \"skip\")\n",
    "\n",
    "pipeline_mj = Pipeline(stages=[gendInd, gend, raceInd, race, va, logm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mj = pipeline_mj.fit(data_mj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mj = model_mj.transform(data_mj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.2824, -0.0777, 0.6497, 1.455, 0.0645])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mj.stages[-1].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous model, none of the coefficients for race are equal to zero, although with so few variables in the model, this isn't as meaningful as if race was a significant predictor in the presence of many other predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='White Caucasian(Non-Hispanic)', Gender='Male', probability=DenseVector([0.1502, 0.8498]), prediction=1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mj.filter(pred.RaceClean == 'White').filter(pred.Gender == 'Male')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='Black(Non-Hispanic)', Gender='Male', probability=DenseVector([0.1783, 0.8217]), prediction=1.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mj.filter(pred.RaceClean == 'Black').filter(pred.Gender == 'Male')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='Hispanic', Gender='Male', probability=DenseVector([0.1406, 0.8594]), prediction=1.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mj.filter(pred.RaceClean == 'Hispanic').filter(pred.Gender == 'Male')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='White Caucasian(Non-Hispanic)', Gender='Female', probability=DenseVector([0.1587, 0.8413]), prediction=1.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mj.filter(pred.RaceClean == 'White').filter(pred.Gender == 'Female')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='Black(Non-Hispanic)', Gender='Female', probability=DenseVector([0.1879, 0.8121]), prediction=1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mj.filter(pred.RaceClean == 'Black').filter(pred.Gender == 'Female')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='Hispanic', Gender='Female', probability=DenseVector([0.1486, 0.8514]), prediction=1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mj.filter(pred.RaceClean == 'Hispanic').filter(pred.Gender == 'Female')\\\n",
    "        .select('Race', 'Gender', 'probability', 'prediction').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this model only uses race and gender as predictors, the prediction will be the same for every white male and every black male (and every other combination of race and gender).\n",
    "\n",
    "In this very basic model, a Black man is predicted to have an 85% chance of being charged with a felony for possession of marijuana, while a white man is predicted to have an 82% chance. \n",
    "\n",
    "Below, we look at the percentages in the data to sanity-check our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+--------------------+\n",
      "|           RaceClean| count|n_felonies|             percent|\n",
      "+--------------------+------+----------+--------------------+\n",
      "|                null|     0|        40|                null|\n",
      "|             Unknown| 18919|       975| 0.05153549341931392|\n",
      "|     American Indian|   771|        34| 0.04409857328145266|\n",
      "|               White|342174|     55906| 0.16338471070274188|\n",
      "|               Black|262707|     47861|  0.1821839539867609|\n",
      "|            Hispanic| 20567|       112|0.005445616764720...|\n",
      "|Asian or Pacific ...|  7218|       970|  0.1343862565807703|\n",
      "|American Indian o...|    74|         2| 0.02702702702702703|\n",
      "+--------------------+------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fel = data.groupBy('RaceClean').agg(F.count(data.RaceClean).alias('count'), \n",
    "                                    F.sum(data.Felony).alias('n_felonies'))\n",
    "\n",
    "fel.withColumn('percent', fel['n_felonies']/fel['count']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+------------------+\n",
      "|           RaceClean|count|n_felonies|           percent|\n",
      "+--------------------+-----+----------+------------------+\n",
      "|                null|    0|         3|              null|\n",
      "|             Unknown|   37|        34| 0.918918918918919|\n",
      "|               White| 1775|      1420|               0.8|\n",
      "|               Black| 2566|      1984|0.7731878409976617|\n",
      "|            Hispanic|    8|         7|             0.875|\n",
      "|Asian or Pacific ...|   56|        48|0.8571428571428571|\n",
      "+--------------------+-----+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fel = data.filter(data.CodeSection == '18.2-248.1').groupBy('RaceClean')\\\n",
    "            .agg(F.count(data.RaceClean).alias('count'), \n",
    "                 F.sum(data.Felony).alias('n_felonies'))\n",
    "\n",
    "fel.withColumn('percent', fel['n_felonies']/fel['count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those charged with marijuana possession, 80% of whites and 77% of Blacks were charged with a felony, both of which are slightly lower than predicted by the model (for both genders).\n",
    "\n",
    "Other races have very small sample sizes, so we can't really draw many conclusions from that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Feature Importance\n",
    "\n",
    "Next, we implement a random forest model to quantify the feature importance further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"Felony\", featuresCol=\"features\", numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=[\"RaceOH\", \"ChargeCodeOH\", \"GenderOH\"], outputCol=\"features\", \n",
    "                     handleInvalid = \"skip\")\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[gendInd, gend, raceInd, race, chargeInd, charge, va, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = pipeline_rf.fit(data)\n",
    "pred_rf = model_rf.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4385, {1: 0.0001, 2: 0.0058, 3: 0.012, 6: 0.0055, 7: 0.0523, 8: 0.0301, 9: 0.0248, 10: 0.0123, 11: 0.0145, 12: 0.0202, 13: 0.0091, 14: 0.005, 16: 0.0065, 17: 0.0052, 18: 0.0245, 20: 0.0011, 21: 0.005, 22: 0.0885, 23: 0.0215, 24: 0.0001, 25: 0.0131, 26: 0.0065, 27: 0.0085, 28: 0.0162, 29: 0.0022, 30: 0.0433, 31: 0.0077, 32: 0.0059, 33: 0.0015, 34: 0.0005, 35: 0.0014, 36: 0.0002, 37: 0.0322, 38: 0.0097, 39: 0.0071, 41: 0.0115, 42: 0.0475, 43: 0.0037, 44: 0.0018, 45: 0.0029, 47: 0.0135, 49: 0.0025, 50: 0.0151, 51: 0.0217, 52: 0.0001, 53: 0.0101, 54: 0.0006, 55: 0.0137, 56: 0.0008, 57: 0.0201, 58: 0.0008, 59: 0.0013, 61: 0.0361, 62: 0.0053, 63: 0.0015, 64: 0.0005, 65: 0.0005, 66: 0.0013, 67: 0.0169, 69: 0.0049, 70: 0.0061, 71: 0.0005, 72: 0.0002, 76: 0.022, 77: 0.0012, 78: 0.0171, 79: 0.0113, 81: 0.0002, 83: 0.0111, 84: 0.0005, 85: 0.0002, 87: 0.0001, 88: 0.0036, 91: 0.0001, 95: 0.0185, 97: 0.0003, 98: 0.0, 100: 0.0014, 101: 0.0127, 102: 0.0149, 104: 0.0065, 108: 0.004, 109: 0.0001, 110: 0.0005, 111: 0.0074, 112: 0.0102, 113: 0.001, 116: 0.0006, 118: 0.0004, 119: 0.0002, 120: 0.0002, 121: 0.0, 123: 0.0, 125: 0.0001, 127: 0.0073, 128: 0.0004, 132: 0.0077, 134: 0.0213, 135: 0.0011, 136: 0.0009, 141: 0.0008, 146: 0.0038, 147: 0.0003, 149: 0.0031, 152: 0.0001, 153: 0.0088, 157: 0.0, 160: 0.0013, 166: 0.0033, 167: 0.0, 175: 0.0007, 178: 0.0035, 180: 0.0019, 181: 0.0005, 183: 0.0005, 186: 0.0006, 187: 0.0067, 196: 0.0017, 197: 0.0002, 201: 0.0001, 203: 0.0001, 205: 0.0008, 213: 0.0016, 217: 0.0001, 231: 0.0003, 236: 0.0012, 241: 0.0055, 257: 0.0019, 259: 0.0015, 262: 0.0001, 263: 0.0102, 267: 0.0001, 272: 0.0002, 280: 0.0003, 281: 0.0015, 284: 0.0001, 285: 0.0002, 291: 0.0014, 305: 0.0001, 309: 0.0016, 315: 0.0015, 325: 0.0003, 345: 0.0003, 367: 0.0001, 402: 0.0012, 431: 0.0005, 447: 0.0001, 532: 0.0001, 544: 0.0, 545: 0.0002, 635: 0.0, 800: 0.0001, 978: 0.0, 1076: 0.0, 1136: 0.0, 4384: 0.0022})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rf = pred_rf.select(\"features\").schema[0].metadata.get('ml_attr').get('attrs').get('binary')\n",
    "\n",
    "# merge_list = numeric_metadata + binary_metadata \n",
    "feature_names = [field['name'] for field in meta_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'RaceOH_White'),\n",
       " (0.00012706110633525647, 'RaceOH_Black'),\n",
       " (0.0058008513585579066, 'RaceOH_Hispanic'),\n",
       " (0.011998627521152817, 'RaceOH_Unknown'),\n",
       " (0.0, 'RaceOH_Asian or Pacific Islander'),\n",
       " (0.0, 'RaceOH_American Indian'),\n",
       " (0.005466628882552965, 'ChargeCodeOH_A.46.2-862'),\n",
       " (0.05230187267937904, 'ChargeCodeOH_B.46.2-301'),\n",
       " (0.030146516747104328, 'ChargeCodeOH_46.2-300'),\n",
       " (0.024756935829529585, 'ChargeCodeOH_18.2-250.1'),\n",
       " (0.012335922179153332, 'ChargeCodeOH_C.46.2-862'),\n",
       " (0.014490057647865429, 'ChargeCodeOH_18.2-250'),\n",
       " (0.02017981376068468, 'ChargeCodeOH_A.18.2-266'),\n",
       " (0.009054333832899723, 'ChargeCodeOH_18.2-388'),\n",
       " (0.004973723378849848, 'ChargeCodeOH_18.2-57')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(model_rf.stages[-1].featureImportances.toArray(), feature_names))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002180120217458102, 'GenderOH_Male')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(model_rf.stages[-1].featureImportances.toArray(), feature_names))[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only races with a non-zero feature importance for predicting whether a crime will be a felony or not are Black, Hispanic and unknown. Several charges have much higher feature importance, and gender also has non-zero feature importance.\n",
    "\n",
    "This matches expectation, since some charges will obviously have much higher rates of felonies than other charges, and some charges will always be either a misdemeanor and other will always be a felony.\n",
    "\n",
    "Next, we again look at just marijuana charges for feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=[\"RaceOH\", \"GenderOH\"], outputCol=\"features\", \n",
    "                     handleInvalid = \"skip\")\n",
    "\n",
    "pipeline_mj = Pipeline(stages=[gendInd, gend, raceInd, race, va, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = pipeline_mj.fit(data_mj)\n",
    "pred_rf = model_rf.transform(data_mj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature names\n",
    "\n",
    "meta_rf = pred_rf.select(\"features\").schema[0].metadata.get('ml_attr').get('attrs').get('binary')\n",
    "\n",
    "# merge_list = numeric_metadata + binary_metadata \n",
    "feature_names = [field['name'] for field in meta_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RaceOH_Black', 0.2576646203782787),\n",
       " ('RaceOH_White', 0.25975752149859244),\n",
       " ('RaceOH_Asian or Pacific Islander', 0.17215317915534445),\n",
       " ('RaceOH_Unknown', 0.17605941299451264),\n",
       " ('GenderOH_Male', 0.13436526597327178)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine names with importances\n",
    "list(zip(feature_names, model_rf.stages[-1].featureImportances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we see that race is a more important factor than gender in determining whether marijuana possession with intent to distribute is a felony or a misdemeanor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
